{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aldi Sulthony Susilo_1101172222_Image Classification 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN69+auFfMb7dgum2kih/rn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aldisulthony/Pemrograman-Python/blob/main/Aldi_Sulthony_Susilo_1101172222_Image_Classification_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCt1VEmPhfm5"
      },
      "source": [
        "Importing the Google Drive cloud database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmUFd29A4Ez0",
        "outputId": "b0ed98d6-f26a-4a62-fc4a-7556bbe139fe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AY0e-g6Et8T3WY9lq--yoZjYxUu730Z_sy8OQrDw2qJoFROQ602VJ0obY0U\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13VrujPdho_k"
      },
      "source": [
        "Importing the folder that contains the dataset needed for image classification modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MXl-6iN4Fel"
      },
      "source": [
        "cd /content/drive/MyDrive/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEKWaelohxKr"
      },
      "source": [
        "List the folder to makesure that the dataset includes in the specified folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2smwlEJd5oVh"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh8aK1_t50sF"
      },
      "source": [
        "# Import necessary modules and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from PIL import Image\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q11V4AvR6p6U"
      },
      "source": [
        "# Create the image path with \"paths\" in the input data dataset directory\n",
        "# List the images and its labels\n",
        "print(\"[INFO loading images..\")\n",
        "imagePaths = paths.list_images(\"dataset\")\n",
        "data = []\n",
        "labels = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgkUThz67UV_"
      },
      "source": [
        "# Loop over the input images using \"for\" function:\n",
        "for imagePath in imagePaths:\n",
        "  # Load the input image from the selected image path\n",
        "  image = Image.open(imagePath)\n",
        "\n",
        "  # Resize it to 64x64 pixels, the pixel intensities to the range [0,1] and then updateour image list\n",
        "  # Conducting the prepocessing and normalize process to the image\n",
        "  image = np.array(image.resize((64,64))) / 255.0 \n",
        "  data.append(image)\n",
        "\n",
        "  # Extract the class label from the path file and update the labels list\n",
        "  label = imagePath.split(os.path.sep)[-2]\n",
        "  labels.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hWOjjG29LZC"
      },
      "source": [
        "# Visualize the input image label list\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5Jnj3fE9QmV"
      },
      "source": [
        "# Encode the input image labels, convert them from strings to integers to make easier for computer to proceed\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D26gCwK91rY"
      },
      "source": [
        "# Visualize the converted input label images\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO0sDwo198Pl"
      },
      "source": [
        "# Perform a training and testing split data for modeling\n",
        "# Using 80% of the data for training and 20% of the data for evaluation\n",
        "(trainX, testX, trainY, testY) = train_test_split(np.array(data), np.array(labels), test_size=0.20, shuffle=True)\n",
        "\n",
        "# Visualize train and test X shape\n",
        "print(trainX.shape)\n",
        "print(testX.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRtk4LzO-jxz"
      },
      "source": [
        "# Conducting Convolutional Neural Network and Fully Connected Feedforward Network\n",
        "\n",
        "# Import necessary modules and packages\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Flatten, Dense\n",
        "\n",
        "# Proceed the CNN stages (2 times of Convolution and Max Pooling)\n",
        "model = Sequential()\n",
        "model.add(Convolution2D(8, (3,3), activation=\"relu\", input_shape=(64,64,3))) # the input shape is supposed to be the same as resize input image [64x64] for RGB image\n",
        "model.add(MaxPool2D(2,2))\n",
        "model.add(Convolution2D(16, (3,3), activation=\"relu\"))\n",
        "model.add(MAxPool2D(2,2))\n",
        "\n",
        "# Conduct the Fully Connected Layer  stages\n",
        "model.add(Flatten) # remap the weight to 1D\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax')) # 5 for attributes that is use for this modeling\n",
        "\n",
        "# Perform the model summary\n",
        "model.summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qWBzMYtBVq-"
      },
      "source": [
        "# Train the model using the Adam Optimizer\n",
        "print('[INFO] training network...')\n",
        "opt = Adam(lr=1e-3, decay=1e-3/50)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rlnd8BKhBxTw"
      },
      "source": [
        "H = model.fit(trainX,trainY, validation_data=(testX, testY,), epochs=25, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbimpoHtB-t6"
      },
      "source": [
        "# Visualixe the trained model\n",
        "\n",
        "# Import Matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(H.history.keys())\n",
        "\n",
        "# Summarize history for accuracy\n",
        "plt.plot(H.history['accuracy'])\n",
        "plt.plot(H.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Summarize history for loss\n",
        "plt.plot(H.history['loss'])\n",
        "plt.plot(H.history['val_loss'])\n",
        "plt.title('Modell Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1KKLF2bDQsD"
      },
      "source": [
        "# Evaluate the model by using F1 Score Table\n",
        "print('[INFO] Evaluating Network...')\n",
        "predictions = model.predict(testX, batch_size=32)\n",
        "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=lb.classes_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjG9TI_tD2n_"
      },
      "source": [
        "# Save the Model\n",
        "model.save('cnnmodel_leaf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqMvVNt1D-Xo"
      },
      "source": [
        "# Perform image testing by using the saved moddel by using cv2\n",
        "\n",
        "# Import necessary modules\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt \n",
        "image_test = 'leaf_test.jpg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyCgf61xEkBc"
      },
      "source": [
        "# Read and Show the image test file by using cv2 module\n",
        "img_array = cv2.imread(image_test)\n",
        "\n",
        "# Read and show the array based image using matplotlib module\n",
        "plt.imshow(img_array)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IfhxAfTFEVF"
      },
      "source": [
        "image_testing = Image.open('leaf_test.jpg')\n",
        "image_testing = np.array(image_testing.resize((64,64))) / 255.0 # based on the image trained model size and normalize phase\n",
        "image_testing.shape # show the testing image shape "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p33hx9L6F2nx"
      },
      "source": [
        "image_testing = np.expand_dims(image_testing, axis=0)\n",
        "print(image_testing.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeDTBM3sGA8e"
      },
      "source": [
        "output = model.predict(image_testing, 1)\n",
        "print(output)\n",
        "print(lb.classes_[output.argmax(Axis=1)])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}